name: Enhanced Testing Pipeline

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  COVERAGE_THRESHOLD: 90
  ACCESSIBILITY_THRESHOLD: 95
  PERFORMANCE_THRESHOLD: 100

jobs:
  # Pre-flight checks
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      should-run-tests: ${{ steps.changes.outputs.should-run }}
      test-types: ${{ steps.determine-tests.outputs.types }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect Changes
        id: changes
        uses: dorny/paths-filter@v2
        with:
          filters: |
            src:
              - 'src/**'
            tests:
              - 'src/**/*.test.*'
              - 'src/**/*.spec.*'
            config:
              - 'package.json'
              - 'vite.config.ts'
              - 'tsconfig.json'

      - name: Determine Test Types
        id: determine-tests
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "types=unit,integration,accessibility,performance,load" >> $GITHUB_OUTPUT
          elif [[ "${{ steps.changes.outputs.src }}" == "true" ]]; then
            echo "types=unit,integration,accessibility,performance" >> $GITHUB_OUTPUT
          else
            echo "types=unit" >> $GITHUB_OUTPUT
          fi

  # Code quality and security
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    needs: pre-flight
    if: needs.pre-flight.outputs.should-run-tests == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Type Check
        run: npm run type-check

      - name: Lint Code
        run: npm run lint

      - name: Format Check
        run: npm run format:check

      - name: Security Audit
        run: npm run security:audit

      - name: Validate Environment Config
        run: npm run env:validate-all

  # Unit and Integration Tests
  unit-integration-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    strategy:
      matrix:
        node-version: [18, 20]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Setup Test Environment
        run: |
          cp .env.example .env.test
          echo "VITE_TEST_MODE=true" >> .env.test

      - name: Run Unit Tests with Coverage
        run: npm run test:coverage:enhanced
        env:
          NODE_ENV: test

      - name: Run Integration Tests
        run: npm run test:integration
        env:
          NODE_ENV: test

      - name: Check Coverage Threshold
        run: |
          COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
          echo "Coverage: $COVERAGE%"
          if (( $(echo "$COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
            echo "❌ Coverage $COVERAGE% is below threshold $COVERAGE_THRESHOLD%"
            exit 1
          fi
          echo "✅ Coverage $COVERAGE% meets threshold $COVERAGE_THRESHOLD%"

      - name: Upload Coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella

      - name: Upload Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.node-version }}
          path: |
            coverage/
            test-results.xml

  # Accessibility Tests
  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: contains(needs.pre-flight.outputs.test-types, 'accessibility')
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Run Accessibility Tests
        run: npm run test:enhanced:a11y
        env:
          NODE_ENV: test

      - name: Check Accessibility Threshold
        run: |
          if [ -f "reports/accessibility-report.json" ]; then
            SCORE=$(jq -r '.score' reports/accessibility-report.json)
            echo "Accessibility Score: $SCORE%"
            if (( $(echo "$SCORE < $ACCESSIBILITY_THRESHOLD" | bc -l) )); then
              echo "❌ Accessibility score $SCORE% is below threshold $ACCESSIBILITY_THRESHOLD%"
              exit 1
            fi
            echo "✅ Accessibility score $SCORE% meets threshold $ACCESSIBILITY_THRESHOLD%"
          fi

      - name: Upload Accessibility Report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: accessibility-report
          path: reports/accessibility-report.*

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: contains(needs.pre-flight.outputs.test-types, 'performance')
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Build Application
        run: npm run build:production

      - name: Start Application
        run: |
          npm run preview:production &
          sleep 10

      - name: Run Performance Tests
        run: npm run test:enhanced:perf
        env:
          NODE_ENV: production

      - name: Run Lighthouse Audit
        run: npm run performance:audit

      - name: Check Performance Threshold
        run: |
          if [ -f "reports/performance-report.json" ]; then
            RENDER_TIME=$(jq -r '.averageRenderTime' reports/performance-report.json)
            echo "Average Render Time: ${RENDER_TIME}ms"
            if (( $(echo "$RENDER_TIME > $PERFORMANCE_THRESHOLD" | bc -l) )); then
              echo "❌ Render time ${RENDER_TIME}ms exceeds threshold ${PERFORMANCE_THRESHOLD}ms"
              exit 1
            fi
            echo "✅ Render time ${RENDER_TIME}ms meets threshold ${PERFORMANCE_THRESHOLD}ms"
          fi

      - name: Upload Performance Report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-report
          path: |
            reports/performance-report.*
            reports/lighthouse.json

  # Load Tests (only on main branch and nightly)
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    if: contains(needs.pre-flight.outputs.test-types, 'load') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Setup Test Database
        run: |
          # Setup test database with sample data
          echo "Setting up test database..."

      - name: Build and Start Application
        run: |
          npm run build:production
          npm run preview:production &
          sleep 15

      - name: Run Load Tests
        run: npm run test:enhanced:load
        env:
          NODE_ENV: production
          TEST_AUTH_TOKEN: ${{ secrets.TEST_AUTH_TOKEN }}
          TEST_USER_ID: ${{ secrets.TEST_USER_ID }}
          TEST_CLINIC_ID: ${{ secrets.TEST_CLINIC_ID }}

      - name: Check Load Test Results
        run: |
          if [ -f "reports/load-test-results.json" ]; then
            ERROR_RATE=$(jq -r '.aggregate.counters["http.codes.4xx"] + .aggregate.counters["http.codes.5xx"]' reports/load-test-results.json)
            TOTAL_REQUESTS=$(jq -r '.aggregate.counters["http.requests"]' reports/load-test-results.json)
            ERROR_PERCENTAGE=$(echo "scale=2; $ERROR_RATE * 100 / $TOTAL_REQUESTS" | bc)
            echo "Error Rate: $ERROR_PERCENTAGE%"
            if (( $(echo "$ERROR_PERCENTAGE > 5" | bc -l) )); then
              echo "❌ Error rate $ERROR_PERCENTAGE% exceeds 5% threshold"
              exit 1
            fi
            echo "✅ Error rate $ERROR_PERCENTAGE% is within acceptable limits"
          fi

      - name: Upload Load Test Report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: load-test-report
          path: reports/load-test-results.*

  # E2E Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [pre-flight, code-quality]
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Build Application
        run: npm run build

      - name: Run E2E Tests
        run: npx playwright test --project=${{ matrix.browser }}
        env:
          NODE_ENV: test

      - name: Upload E2E Report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-report-${{ matrix.browser }}
          path: |
            playwright-report/
            test-results/

  # Comprehensive Report Generation
  generate-report:
    name: Generate Comprehensive Report
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, accessibility-tests, performance-tests, e2e-tests]
    if: always()
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Download All Artifacts
        uses: actions/download-artifact@v3

      - name: Generate Comprehensive Report
        run: node scripts/generate-comprehensive-report.js

      - name: Upload Comprehensive Report
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-report
          path: reports/comprehensive-report.*

      - name: Comment PR with Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('reports/comprehensive-report.json')) {
              const report = JSON.parse(fs.readFileSync('reports/comprehensive-report.json', 'utf8'));
              const comment = `
              ## 🧪 Enhanced Testing Results
              
              | Test Type | Status | Score/Coverage |
              |-----------|--------|----------------|
              | Unit Tests | ${report.unit?.success ? '✅' : '❌'} | ${report.unit?.coverage?.percentage || 'N/A'}% |
              | Integration | ${report.integration?.success ? '✅' : '❌'} | ${report.integration?.tests || 'N/A'} tests |
              | Accessibility | ${report.accessibility?.success ? '✅' : '❌'} | ${report.accessibility?.score || 'N/A'}% |
              | Performance | ${report.performance?.success ? '✅' : '❌'} | ${report.performance?.renderTime || 'N/A'}ms |
              | E2E Tests | ${report.e2e?.success ? '✅' : '❌'} | ${report.e2e?.tests || 'N/A'} tests |
              
              **Overall Success Rate:** ${report.summary?.successRate || 'N/A'}%
              
              ${report.recommendations?.length ? '### 📋 Recommendations:\n' + report.recommendations.map(r => `- ${r}`).join('\n') : ''}
              `;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

  # Deployment Gate
  deployment-gate:
    name: Deployment Gate
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, accessibility-tests, performance-tests, e2e-tests]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Check All Tests Passed
        run: |
          echo "Checking deployment gate..."
          if [[ "${{ needs.unit-integration-tests.result }}" != "success" ]]; then
            echo "❌ Unit/Integration tests failed"
            exit 1
          fi
          if [[ "${{ needs.accessibility-tests.result }}" != "success" ]]; then
            echo "❌ Accessibility tests failed"
            exit 1
          fi
          if [[ "${{ needs.performance-tests.result }}" != "success" ]]; then
            echo "❌ Performance tests failed"
            exit 1
          fi
          if [[ "${{ needs.e2e-tests.result }}" != "success" ]]; then
            echo "❌ E2E tests failed"
            exit 1
          fi
          echo "✅ All quality gates passed - Ready for deployment"

      - name: Trigger Deployment
        if: success()
        run: |
          echo "🚀 Triggering deployment pipeline..."
          # Add your deployment trigger here
